{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "683080de-5168-4fe7-871a-fc31831a13f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PS Prediction III: Financial Econometrics and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abbcfa6-5bcb-43e8-af42-8863aaa5d9b1",
   "metadata": {},
   "source": [
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7969df9f-f920-473d-a816-a2a85dc3ab72",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Question 1: Data Cleaning and Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b35dc-9d92-4cf1-887f-3912a353cbf8",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f668fe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wrds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5602ebcd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\urkes\\anaconda3\\lib\\site-packages (2.13.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Collecting h5py>=2.9.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading h5py-3.10.0-cp38-cp38-win_amd64.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.22.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.59.2)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.23.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.2)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Downloading h5py-3.10.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.7 MB 7.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 0.7/2.7 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.4/2.7 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.1/2.7 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 12.4 MB/s eta 0:00:00\n",
      "Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "   ---------------------------------------- 0.0/226.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 226.7/226.7 kB 13.5 MB/s eta 0:00:00\n",
      "Installing collected packages: werkzeug, typing-extensions, h5py\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "Successfully installed h5py-3.10.0 typing-extensions-4.5.0 werkzeug-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2396b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade scipy numba daal4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6111033-c038-491a-9aed-b11a0736ee49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "from scipy.stats import norm, uniform, skew, kurtosis\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "import os\n",
    "from arch.univariate import ConstantMean, GARCH, Normal\n",
    "from arch.__future__ import reindexing\n",
    "from arch.univariate import arch_model\n",
    "from arch import arch_model\n",
    "from arch.univariate import GARCH\n",
    "from arch.__future__ import reindexing\n",
    "import yfinance as yf\n",
    "import wrds\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02fcf03c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9b58a24-53ac-4888-8845-ac2c66c44f32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#item = pd.read_csv(\"datashare.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c845e950-928f-415e-8e7c-777a9ef62d94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#items_permno = pd.Series(item['permno'].unique()).sort_values(ascending=True).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1121461d-70ed-44e3-841b-66b96d6c7745",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date range: 19570131 to 20211231\n"
     ]
    }
   ],
   "source": [
    "#item['DATE'] = pd.to_datetime(item['DATE'], format='%Y%m%d', errors='coerce')\n",
    "#item['DATE'] = item['DATE'].dt.strftime('%Y%m%d')\n",
    "#print(\"date range:\", item['DATE'].min(), \"to\", item['DATE'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30cf615-9a76-4815-97c8-7c6b1cdc28c8",
   "metadata": {},
   "source": [
    "get prices of all securities in datashare from Kelly et Al. through the wrds package by mapping wrds stock returns to our item through the \"permno\" stock identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd4ef27-f074-439b-8125-d13460186df1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db = wrds.Connection(wrds_username='urkesh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b53175-0713-4a9d-b0ed-5b473387b3cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "permno_string = ', '.join(str(permno) for permno in items_permno)\n",
    "monthly_return_query = f\"\"\"\n",
    "SELECT permno, date, ret AS monthly_return\n",
    "FROM crsp.msf\n",
    "WHERE permno IN ({permno_string})\n",
    "AND date >= '1957-01-31' AND date <= '2021-12-31';\n",
    "\"\"\"\n",
    "monthly_return_data = db.raw_sql(monthly_return_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25775d9d-3fbc-49f3-89db-91eb4b367a1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#merge the datasets\n",
    "data = item.merge(monthly_return_data, how='left', left_on=['permno', 'DATE'], right_on=['permno', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0560d492-0bc2-4206-9ce9-9cabcbb21b89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\FinancialEcon Machine Learning\\data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "180d2540-7cc7-4445-a891-cbd28988e099",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.drop(\"date\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b516a2d-1ca1-4f8a-ba7c-e8dab3410297",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64 datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "data['date'] = pd.to_datetime(data['DATE'], format='%Y%m%d', errors='coerce')\n",
    "\n",
    "data['permno'] = pd.to_numeric(data['permno'], downcast='integer', errors='coerce')\n",
    "\n",
    "data['permno'] = data['permno'].astype('int64')\n",
    "\n",
    "print(data['permno'].dtype, data['date'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49c74cc7-9990-4c22-9d16-9f9c4717c8e8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>permno</th>\n",
       "      <th>DATE</th>\n",
       "      <th>mvel1</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>chmom</th>\n",
       "      <th>dolvol</th>\n",
       "      <th>idiovol</th>\n",
       "      <th>indmom</th>\n",
       "      <th>mom1m</th>\n",
       "      <th>...</th>\n",
       "      <th>baspread</th>\n",
       "      <th>ill</th>\n",
       "      <th>maxret</th>\n",
       "      <th>retvol</th>\n",
       "      <th>std_dolvol</th>\n",
       "      <th>std_turn</th>\n",
       "      <th>zerotrade</th>\n",
       "      <th>sic2</th>\n",
       "      <th>monthly_return</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10006</td>\n",
       "      <td>19570131</td>\n",
       "      <td>8.224900e+04</td>\n",
       "      <td>1.122846</td>\n",
       "      <td>1.260784</td>\n",
       "      <td>0.047180</td>\n",
       "      <td>9.569953</td>\n",
       "      <td>0.025742</td>\n",
       "      <td>0.046433</td>\n",
       "      <td>0.044843</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013234</td>\n",
       "      <td>9.411565e-08</td>\n",
       "      <td>0.015453</td>\n",
       "      <td>0.008058</td>\n",
       "      <td>0.355638</td>\n",
       "      <td>0.460420</td>\n",
       "      <td>1.120996e-07</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.064378</td>\n",
       "      <td>1957-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10014</td>\n",
       "      <td>19570131</td>\n",
       "      <td>3.903375e+03</td>\n",
       "      <td>0.426734</td>\n",
       "      <td>0.182102</td>\n",
       "      <td>-0.275641</td>\n",
       "      <td>6.237836</td>\n",
       "      <td>0.072103</td>\n",
       "      <td>0.046433</td>\n",
       "      <td>-0.086957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033305</td>\n",
       "      <td>6.610609e-06</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.033495</td>\n",
       "      <td>1.152126</td>\n",
       "      <td>1.169610</td>\n",
       "      <td>9.229146e-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>1957-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10022</td>\n",
       "      <td>19570131</td>\n",
       "      <td>9.273250e+03</td>\n",
       "      <td>1.066449</td>\n",
       "      <td>1.137313</td>\n",
       "      <td>-0.025490</td>\n",
       "      <td>7.008844</td>\n",
       "      <td>0.027648</td>\n",
       "      <td>0.046433</td>\n",
       "      <td>-0.060377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016023</td>\n",
       "      <td>2.286832e-06</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.015589</td>\n",
       "      <td>0.815777</td>\n",
       "      <td>0.679803</td>\n",
       "      <td>1.181757e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>1957-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10030</td>\n",
       "      <td>19570131</td>\n",
       "      <td>5.446588e+04</td>\n",
       "      <td>0.926038</td>\n",
       "      <td>0.857547</td>\n",
       "      <td>0.018171</td>\n",
       "      <td>9.825337</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.046433</td>\n",
       "      <td>0.044633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015295</td>\n",
       "      <td>1.464273e-07</td>\n",
       "      <td>0.039326</td>\n",
       "      <td>0.015849</td>\n",
       "      <td>0.739302</td>\n",
       "      <td>1.333656</td>\n",
       "      <td>6.126699e-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.047091</td>\n",
       "      <td>1957-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10057</td>\n",
       "      <td>19570131</td>\n",
       "      <td>4.025000e+04</td>\n",
       "      <td>1.247748</td>\n",
       "      <td>1.556875</td>\n",
       "      <td>0.025785</td>\n",
       "      <td>7.901007</td>\n",
       "      <td>0.025506</td>\n",
       "      <td>0.046433</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005954</td>\n",
       "      <td>1.380375e-06</td>\n",
       "      <td>0.056856</td>\n",
       "      <td>0.019945</td>\n",
       "      <td>0.755510</td>\n",
       "      <td>0.410391</td>\n",
       "      <td>3.315790e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.090062</td>\n",
       "      <td>1957-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4117295</th>\n",
       "      <td>93423</td>\n",
       "      <td>20211231</td>\n",
       "      <td>3.144398e+06</td>\n",
       "      <td>1.923076</td>\n",
       "      <td>3.698221</td>\n",
       "      <td>-0.673385</td>\n",
       "      <td>16.305232</td>\n",
       "      <td>0.062619</td>\n",
       "      <td>0.491455</td>\n",
       "      <td>-0.110868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043829</td>\n",
       "      <td>3.698841e-10</td>\n",
       "      <td>0.073435</td>\n",
       "      <td>0.029678</td>\n",
       "      <td>0.399725</td>\n",
       "      <td>9.215947</td>\n",
       "      <td>5.031856e-09</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.164342</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4117296</th>\n",
       "      <td>93426</td>\n",
       "      <td>20211231</td>\n",
       "      <td>4.326610e+05</td>\n",
       "      <td>1.224523</td>\n",
       "      <td>1.499457</td>\n",
       "      <td>-0.061462</td>\n",
       "      <td>12.419552</td>\n",
       "      <td>0.033723</td>\n",
       "      <td>0.346308</td>\n",
       "      <td>0.007040</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025875</td>\n",
       "      <td>1.097624e-08</td>\n",
       "      <td>0.046055</td>\n",
       "      <td>0.019302</td>\n",
       "      <td>0.481331</td>\n",
       "      <td>1.649750</td>\n",
       "      <td>3.023395e-08</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.081270</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4117297</th>\n",
       "      <td>93427</td>\n",
       "      <td>20211231</td>\n",
       "      <td>4.092710e+06</td>\n",
       "      <td>0.887083</td>\n",
       "      <td>0.786917</td>\n",
       "      <td>-0.080295</td>\n",
       "      <td>14.884834</td>\n",
       "      <td>0.045395</td>\n",
       "      <td>0.346308</td>\n",
       "      <td>0.151667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029966</td>\n",
       "      <td>8.593845e-10</td>\n",
       "      <td>0.131563</td>\n",
       "      <td>0.032861</td>\n",
       "      <td>0.440057</td>\n",
       "      <td>2.444487</td>\n",
       "      <td>2.224496e-08</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.071545</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4117298</th>\n",
       "      <td>93434</td>\n",
       "      <td>20211231</td>\n",
       "      <td>1.130478e+05</td>\n",
       "      <td>0.512942</td>\n",
       "      <td>0.263110</td>\n",
       "      <td>-0.543760</td>\n",
       "      <td>12.243872</td>\n",
       "      <td>0.088124</td>\n",
       "      <td>0.270005</td>\n",
       "      <td>-0.319347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069943</td>\n",
       "      <td>1.145228e-07</td>\n",
       "      <td>0.036932</td>\n",
       "      <td>0.035858</td>\n",
       "      <td>0.968425</td>\n",
       "      <td>4.557546</td>\n",
       "      <td>3.155353e-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.065069</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4117299</th>\n",
       "      <td>93436</td>\n",
       "      <td>20211231</td>\n",
       "      <td>1.149642e+09</td>\n",
       "      <td>1.504264</td>\n",
       "      <td>2.262812</td>\n",
       "      <td>0.729456</td>\n",
       "      <td>18.992410</td>\n",
       "      <td>0.081092</td>\n",
       "      <td>0.223504</td>\n",
       "      <td>0.027612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056249</td>\n",
       "      <td>9.679103e-13</td>\n",
       "      <td>0.084910</td>\n",
       "      <td>0.044202</td>\n",
       "      <td>0.381912</td>\n",
       "      <td>11.699841</td>\n",
       "      <td>3.240135e-09</td>\n",
       "      <td>37.0</td>\n",
       "      <td>-0.076855</td>\n",
       "      <td>2021-12-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4117300 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         permno      DATE         mvel1      beta    betasq     chmom  \\\n",
       "0         10006  19570131  8.224900e+04  1.122846  1.260784  0.047180   \n",
       "1         10014  19570131  3.903375e+03  0.426734  0.182102 -0.275641   \n",
       "2         10022  19570131  9.273250e+03  1.066449  1.137313 -0.025490   \n",
       "3         10030  19570131  5.446588e+04  0.926038  0.857547  0.018171   \n",
       "4         10057  19570131  4.025000e+04  1.247748  1.556875  0.025785   \n",
       "...         ...       ...           ...       ...       ...       ...   \n",
       "4117295   93423  20211231  3.144398e+06  1.923076  3.698221 -0.673385   \n",
       "4117296   93426  20211231  4.326610e+05  1.224523  1.499457 -0.061462   \n",
       "4117297   93427  20211231  4.092710e+06  0.887083  0.786917 -0.080295   \n",
       "4117298   93434  20211231  1.130478e+05  0.512942  0.263110 -0.543760   \n",
       "4117299   93436  20211231  1.149642e+09  1.504264  2.262812  0.729456   \n",
       "\n",
       "            dolvol   idiovol    indmom     mom1m  ...  baspread           ill  \\\n",
       "0         9.569953  0.025742  0.046433  0.044843  ...  0.013234  9.411565e-08   \n",
       "1         6.237836  0.072103  0.046433 -0.086957  ...  0.033305  6.610609e-06   \n",
       "2         7.008844  0.027648  0.046433 -0.060377  ...  0.016023  2.286832e-06   \n",
       "3         9.825337  0.021700  0.046433  0.044633  ...  0.015295  1.464273e-07   \n",
       "4         7.901007  0.025506  0.046433  0.086667  ...  0.005954  1.380375e-06   \n",
       "...            ...       ...       ...       ...  ...       ...           ...   \n",
       "4117295  16.305232  0.062619  0.491455 -0.110868  ...  0.043829  3.698841e-10   \n",
       "4117296  12.419552  0.033723  0.346308  0.007040  ...  0.025875  1.097624e-08   \n",
       "4117297  14.884834  0.045395  0.346308  0.151667  ...  0.029966  8.593845e-10   \n",
       "4117298  12.243872  0.088124  0.270005 -0.319347  ...  0.069943  1.145228e-07   \n",
       "4117299  18.992410  0.081092  0.223504  0.027612  ...  0.056249  9.679103e-13   \n",
       "\n",
       "           maxret    retvol  std_dolvol   std_turn     zerotrade  sic2  \\\n",
       "0        0.015453  0.008058    0.355638   0.460420  1.120996e-07  37.0   \n",
       "1        0.047619  0.033495    1.152126   1.169610  9.229146e-08   NaN   \n",
       "2        0.020833  0.015589    0.815777   0.679803  1.181757e-07   NaN   \n",
       "3        0.039326  0.015849    0.739302   1.333656  6.126699e-08   NaN   \n",
       "4        0.056856  0.019945    0.755510   0.410391  3.315790e+00   NaN   \n",
       "...           ...       ...         ...        ...           ...   ...   \n",
       "4117295  0.073435  0.029678    0.399725   9.215947  5.031856e-09  79.0   \n",
       "4117296  0.046055  0.019302    0.481331   1.649750  3.023395e-08  36.0   \n",
       "4117297  0.131563  0.032861    0.440057   2.444487  2.224496e-08  36.0   \n",
       "4117298  0.036932  0.035858    0.968425   4.557546  3.155353e-08   1.0   \n",
       "4117299  0.084910  0.044202    0.381912  11.699841  3.240135e-09  37.0   \n",
       "\n",
       "         monthly_return       date  \n",
       "0              0.064378 1957-01-31  \n",
       "1              0.095238 1957-01-31  \n",
       "2              0.102041 1957-01-31  \n",
       "3             -0.047091 1957-01-31  \n",
       "4             -0.090062 1957-01-31  \n",
       "...                 ...        ...  \n",
       "4117295        0.164342 2021-12-31  \n",
       "4117296        0.081270 2021-12-31  \n",
       "4117297        0.071545 2021-12-31  \n",
       "4117298       -0.065069 2021-12-31  \n",
       "4117299       -0.076855 2021-12-31  \n",
       "\n",
       "[4117300 rows x 99 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac65f841",
   "metadata": {},
   "source": [
    "## Extracting the required data and leave the rest out\n",
    "\n",
    "## mom1m, mom12m, ep, beta, bm, idiovol, mvel1, operprof, roaq, zerotrade, turn, invest, permno, date,  monthly_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9bf6f532",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_data = data[['permno', 'date', 'monthly_return', 'mom1m', 'mom12m', 'ep', 'beta', 'bm',\n",
    "                      'idiovol', 'mvel1', 'operprof', 'roaq', 'zerotrade', 'turn', 'invest']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4658b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c947549",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "permno                  0\n",
       "date                    0\n",
       "monthly_return      20488\n",
       "mom1m               31738\n",
       "mom12m             339105\n",
       "ep                1030000\n",
       "beta               400564\n",
       "bm                1074711\n",
       "idiovol            400564\n",
       "mvel1                3070\n",
       "operprof          1395347\n",
       "roaq              1699393\n",
       "zerotrade          309813\n",
       "turn               350960\n",
       "invest            1420104\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b6cf93dd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\urkes\\AppData\\Local\\Temp\\ipykernel_41792\\2536602564.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['date'] = pd.to_datetime(filtered_data['date'], format='%Y%m%d')\n",
      "C:\\Users\\urkes\\AppData\\Local\\Temp\\ipykernel_41792\\2536602564.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['year_month'] = filtered_data['date'].dt.to_period('M')\n",
      "C:\\Users\\urkes\\AppData\\Local\\Temp\\ipykernel_41792\\2536602564.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[col] = filtered_data.groupby('year_month')[col].transform(lambda x: x.fillna(x.median()))\n"
     ]
    }
   ],
   "source": [
    "filtered_data['date'] = pd.to_datetime(filtered_data['date'], format='%Y%m%d')\n",
    "filtered_data_cols = list(filtered_data.columns.values)\n",
    "filtered_data['year_month'] = filtered_data['date'].dt.to_period('M')\n",
    "grouped = filtered_data.groupby([filtered_data['date'].dt.month, filtered_data['date'].dt.year,'permno'])\n",
    "\n",
    "for col in filtered_data_cols[3:]:\n",
    "    filtered_data[col] = filtered_data.groupby('year_month')[col].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c96e91f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "permno                 0\n",
       "date                   0\n",
       "monthly_return     20488\n",
       "mom1m                  0\n",
       "mom12m                 0\n",
       "ep                 31991\n",
       "beta                   0\n",
       "bm                 72077\n",
       "idiovol                0\n",
       "mvel1                  0\n",
       "operprof           83423\n",
       "roaq              329143\n",
       "zerotrade              0\n",
       "turn                   0\n",
       "invest             51706\n",
       "year_month             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d2f48783",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del filtered_data['year_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd943fcd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\urkes\\AppData\\Local\\Temp\\ipykernel_41792\\2883897418.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['monthly_return'] = filtered_data['monthly_return'].shift(+1)\n"
     ]
    }
   ],
   "source": [
    "filtered_data['monthly_return'] = filtered_data['monthly_return'].shift(+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "561cc7c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#shifted monthly return\n",
    "filtered_data = filtered_data.sort_values(by=['permno', 'date'])\n",
    "filtered_data['shifted_return'] = filtered_data.groupby('permno')['monthly_return'].shift(-1)\n",
    "filtered_data = filtered_data.groupby('permno').apply(lambda group: group.iloc[1:-1]).reset_index(drop=True)\n",
    "filtered_data = filtered_data.sort_values(by=['permno', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a569863-d725-426f-aa10-f968d2100c5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_data = filtered_data.sort_values(by=\"date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c8e3aa",
   "metadata": {},
   "source": [
    "## Since the explain variables are strictly limited to those 12 variables, we may have to remove data this time to avoid missing data issue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1326dadd-99c8-459a-a0ed-bd776b32bb0d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Question 2: Implement AdaBoost and NN2 from Gu et al. (2020) to predict next month excess returns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90fb5ac",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "461654c8-f17a-4ceb-9d93-453b7b121330",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filtered_data = filtered_data.dropna(subset=['shifted_return'] + list(filtered_data.columns[3:]))\n",
    "common_index = filtered_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "24c11c9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#common_index = filtered_data.dropna(subset=['shifted_return'] + list(filtered_data.columns[3:])).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "222be869",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:, 2:-1]\n",
    "y = filtered_data['shifted_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "62cd6f1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_start = '1957-01-31'\n",
    "training_end = '1989-12-31'\n",
    "validating_start = '1990-01-31'\n",
    "validating_end = '2004-12-31'\n",
    "testing_start = '2005-01-31'\n",
    "testing_end = '2020-12-31'\n",
    "\n",
    "training_mask = (filtered_data['date'] >= training_start) & (filtered_data['date'] <= training_end)\n",
    "training_index = filtered_data[training_mask].index.intersection(common_index)\n",
    "X_train = X.loc[training_index]\n",
    "y_train = y.loc[training_index]\n",
    "\n",
    "validating_mask = (filtered_data['date'] >= validating_start) & (filtered_data['date'] <= validating_end)\n",
    "validating_index = filtered_data[validating_mask].index.intersection(common_index)\n",
    "X_validate = X.loc[validating_index]\n",
    "y_validate = y.loc[validating_index]\n",
    "\n",
    "testing_mask = (filtered_data['date'] >= testing_start) & (filtered_data['date'] <= testing_end)\n",
    "testing_index = filtered_data[testing_mask].index.intersection(common_index)\n",
    "X_test = X.loc[testing_index]\n",
    "y_test = y.loc[testing_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4385ed",
   "metadata": {},
   "source": [
    "## Standardize the predictor variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fb5e6c01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mvel1             744756.497445\n",
       "beta                   1.007594\n",
       "betasq                 1.451807\n",
       "chmom                  0.002983\n",
       "dolvol                10.157856\n",
       "                      ...      \n",
       "std_dolvol             0.968482\n",
       "std_turn               3.522099\n",
       "zerotrade              2.071054\n",
       "sic2                  46.898443\n",
       "monthly_return         0.012968\n",
       "Length: 96, dtype: float64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4dbfdd0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mvel1             6.090013e+06\n",
       "beta              6.563374e-01\n",
       "betasq            1.721748e+00\n",
       "chmom             5.209434e-01\n",
       "dolvol            2.704940e+00\n",
       "                      ...     \n",
       "std_dolvol        3.947385e-01\n",
       "std_turn          7.616800e+00\n",
       "zerotrade         4.140889e+00\n",
       "sic2              1.979737e+01\n",
       "monthly_return    1.749351e-01\n",
       "Length: 96, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aaf31809",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mvel1</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>chmom</th>\n",
       "      <th>dolvol</th>\n",
       "      <th>idiovol</th>\n",
       "      <th>indmom</th>\n",
       "      <th>mom1m</th>\n",
       "      <th>mom6m</th>\n",
       "      <th>mom12m</th>\n",
       "      <th>...</th>\n",
       "      <th>ms</th>\n",
       "      <th>baspread</th>\n",
       "      <th>ill</th>\n",
       "      <th>maxret</th>\n",
       "      <th>retvol</th>\n",
       "      <th>std_dolvol</th>\n",
       "      <th>std_turn</th>\n",
       "      <th>zerotrade</th>\n",
       "      <th>sic2</th>\n",
       "      <th>monthly_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>631250</th>\n",
       "      <td>-0.121382</td>\n",
       "      <td>-0.257343</td>\n",
       "      <td>-0.434678</td>\n",
       "      <td>-0.141501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.332728</td>\n",
       "      <td>0.169723</td>\n",
       "      <td>-0.000703</td>\n",
       "      <td>-0.335023</td>\n",
       "      <td>-0.311935</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.034417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.293017</td>\n",
       "      <td>-0.237251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.207177</td>\n",
       "      <td>0.512167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378923</th>\n",
       "      <td>-0.121411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.161919</td>\n",
       "      <td>-0.789155</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.915208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.995224</td>\n",
       "      <td>-0.313645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.410390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941114</th>\n",
       "      <td>-0.120258</td>\n",
       "      <td>1.303956</td>\n",
       "      <td>1.173553</td>\n",
       "      <td>-1.983773</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.629709</td>\n",
       "      <td>-0.569847</td>\n",
       "      <td>2.282837</td>\n",
       "      <td>-1.452141</td>\n",
       "      <td>-0.164121</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.066344</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.655041</td>\n",
       "      <td>1.185106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.025601</td>\n",
       "      <td>1.098465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480250</th>\n",
       "      <td>-0.121088</td>\n",
       "      <td>0.107185</td>\n",
       "      <td>-0.168343</td>\n",
       "      <td>0.664888</td>\n",
       "      <td>-1.934393</td>\n",
       "      <td>0.395815</td>\n",
       "      <td>-0.126574</td>\n",
       "      <td>0.288519</td>\n",
       "      <td>0.117893</td>\n",
       "      <td>-0.461645</td>\n",
       "      <td>...</td>\n",
       "      <td>1.452767</td>\n",
       "      <td>0.684538</td>\n",
       "      <td>1.649493</td>\n",
       "      <td>2.047673</td>\n",
       "      <td>1.937074</td>\n",
       "      <td>-0.187137</td>\n",
       "      <td>-0.437383</td>\n",
       "      <td>2.586777</td>\n",
       "      <td>-0.550500</td>\n",
       "      <td>-0.074131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638100</th>\n",
       "      <td>-0.121067</td>\n",
       "      <td>-0.726943</td>\n",
       "      <td>-0.679777</td>\n",
       "      <td>1.394868</td>\n",
       "      <td>-1.172321</td>\n",
       "      <td>0.053312</td>\n",
       "      <td>0.490212</td>\n",
       "      <td>-0.070706</td>\n",
       "      <td>1.313284</td>\n",
       "      <td>0.057806</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266800</td>\n",
       "      <td>-0.108473</td>\n",
       "      <td>-0.212552</td>\n",
       "      <td>-0.995224</td>\n",
       "      <td>-1.195616</td>\n",
       "      <td>2.589024</td>\n",
       "      <td>-0.384862</td>\n",
       "      <td>3.188126</td>\n",
       "      <td>-1.358688</td>\n",
       "      <td>-0.074131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563609</th>\n",
       "      <td>-0.121218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.646065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.125388</td>\n",
       "      <td>-0.951386</td>\n",
       "      <td>-0.973081</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.301941</td>\n",
       "      <td>-0.130267</td>\n",
       "      <td>0.308875</td>\n",
       "      <td>1.165694</td>\n",
       "      <td>0.251013</td>\n",
       "      <td>0.084772</td>\n",
       "      <td>0.602326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.391709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139779</th>\n",
       "      <td>-0.026447</td>\n",
       "      <td>-0.462882</td>\n",
       "      <td>-0.555534</td>\n",
       "      <td>-0.745852</td>\n",
       "      <td>0.845503</td>\n",
       "      <td>-0.871606</td>\n",
       "      <td>0.237283</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>-0.295894</td>\n",
       "      <td>0.292754</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.626347</td>\n",
       "      <td>-0.212395</td>\n",
       "      <td>-0.729053</td>\n",
       "      <td>-0.976514</td>\n",
       "      <td>-1.188949</td>\n",
       "      <td>-0.375997</td>\n",
       "      <td>-0.500147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455863</th>\n",
       "      <td>-0.120070</td>\n",
       "      <td>-0.265197</td>\n",
       "      <td>-0.439684</td>\n",
       "      <td>-0.374975</td>\n",
       "      <td>-2.270466</td>\n",
       "      <td>-0.353853</td>\n",
       "      <td>0.373003</td>\n",
       "      <td>0.667162</td>\n",
       "      <td>0.201641</td>\n",
       "      <td>0.896949</td>\n",
       "      <td>...</td>\n",
       "      <td>1.452767</td>\n",
       "      <td>0.579462</td>\n",
       "      <td>5.635174</td>\n",
       "      <td>0.115022</td>\n",
       "      <td>-0.261574</td>\n",
       "      <td>3.455172</td>\n",
       "      <td>-0.416964</td>\n",
       "      <td>-0.500147</td>\n",
       "      <td>1.570995</td>\n",
       "      <td>0.065294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122279</th>\n",
       "      <td>-0.076851</td>\n",
       "      <td>0.417800</td>\n",
       "      <td>0.111070</td>\n",
       "      <td>0.663382</td>\n",
       "      <td>0.299876</td>\n",
       "      <td>-0.738545</td>\n",
       "      <td>-0.176193</td>\n",
       "      <td>-0.211143</td>\n",
       "      <td>0.683385</td>\n",
       "      <td>0.084797</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.511946</td>\n",
       "      <td>-0.210228</td>\n",
       "      <td>-0.402452</td>\n",
       "      <td>-0.605954</td>\n",
       "      <td>-1.344830</td>\n",
       "      <td>-0.401906</td>\n",
       "      <td>-0.500147</td>\n",
       "      <td>-0.499988</td>\n",
       "      <td>0.093999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929261</th>\n",
       "      <td>-0.073960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.722899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.932225</td>\n",
       "      <td>-0.293102</td>\n",
       "      <td>0.156910</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.511509</td>\n",
       "      <td>-0.212029</td>\n",
       "      <td>-0.676782</td>\n",
       "      <td>-0.800924</td>\n",
       "      <td>-1.098571</td>\n",
       "      <td>-0.285792</td>\n",
       "      <td>-0.500147</td>\n",
       "      <td>0.611271</td>\n",
       "      <td>-0.211051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1150885 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            mvel1      beta    betasq     chmom    dolvol   idiovol    indmom  \\\n",
       "631250  -0.121382 -0.257343 -0.434678 -0.141501       NaN  0.332728  0.169723   \n",
       "378923  -0.121411       NaN       NaN       NaN       NaN       NaN -1.161919   \n",
       "941114  -0.120258  1.303956  1.173553 -1.983773       NaN  1.629709 -0.569847   \n",
       "1480250 -0.121088  0.107185 -0.168343  0.664888 -1.934393  0.395815 -0.126574   \n",
       "1638100 -0.121067 -0.726943 -0.679777  1.394868 -1.172321  0.053312  0.490212   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "1563609 -0.121218       NaN       NaN       NaN -0.646065       NaN -1.125388   \n",
       "139779  -0.026447 -0.462882 -0.555534 -0.745852  0.845503 -0.871606  0.237283   \n",
       "1455863 -0.120070 -0.265197 -0.439684 -0.374975 -2.270466 -0.353853  0.373003   \n",
       "122279  -0.076851  0.417800  0.111070  0.663382  0.299876 -0.738545 -0.176193   \n",
       "1929261 -0.073960       NaN       NaN       NaN  0.722899       NaN -0.932225   \n",
       "\n",
       "            mom1m     mom6m    mom12m  ...        ms  baspread       ill  \\\n",
       "631250  -0.000703 -0.335023 -0.311935  ...       NaN  1.034417       NaN   \n",
       "378923  -0.789155       NaN       NaN  ...       NaN  2.915208       NaN   \n",
       "941114   2.282837 -1.452141 -0.164121  ...       NaN -0.066344       NaN   \n",
       "1480250  0.288519  0.117893 -0.461645  ...  1.452767  0.684538  1.649493   \n",
       "1638100 -0.070706  1.313284  0.057806  ...  0.266800 -0.108473 -0.212552   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "1563609 -0.951386 -0.973081       NaN  ...       NaN  0.301941 -0.130267   \n",
       "139779   0.003161 -0.295894  0.292754  ...       NaN -0.626347 -0.212395   \n",
       "1455863  0.667162  0.201641  0.896949  ...  1.452767  0.579462  5.635174   \n",
       "122279  -0.211143  0.683385  0.084797  ...       NaN -0.511946 -0.210228   \n",
       "1929261 -0.293102  0.156910       NaN  ...       NaN -0.511509 -0.212029   \n",
       "\n",
       "           maxret    retvol  std_dolvol  std_turn  zerotrade      sic2  \\\n",
       "631250  -0.293017 -0.237251         NaN       NaN        NaN  0.207177   \n",
       "378923  -0.995224 -0.313645         NaN       NaN        NaN       NaN   \n",
       "941114   1.655041  1.185106         NaN       NaN        NaN  2.025601   \n",
       "1480250  2.047673  1.937074   -0.187137 -0.437383   2.586777 -0.550500   \n",
       "1638100 -0.995224 -1.195616    2.589024 -0.384862   3.188126 -1.358688   \n",
       "...           ...       ...         ...       ...        ...       ...   \n",
       "1563609  0.308875  1.165694    0.251013  0.084772   0.602326       NaN   \n",
       "139779  -0.729053 -0.976514   -1.188949 -0.375997  -0.500147       NaN   \n",
       "1455863  0.115022 -0.261574    3.455172 -0.416964  -0.500147  1.570995   \n",
       "122279  -0.402452 -0.605954   -1.344830 -0.401906  -0.500147 -0.499988   \n",
       "1929261 -0.676782 -0.800924   -1.098571 -0.285792  -0.500147  0.611271   \n",
       "\n",
       "         monthly_return  \n",
       "631250         0.512167  \n",
       "378923        -0.410390  \n",
       "941114         1.098465  \n",
       "1480250       -0.074131  \n",
       "1638100       -0.074131  \n",
       "...                 ...  \n",
       "1563609       -0.391709  \n",
       "139779         0.014002  \n",
       "1455863        0.065294  \n",
       "122279         0.093999  \n",
       "1929261       -0.211051  \n",
       "\n",
       "[1150885 rows x 96 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train - X_train.mean()) / X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d45ecd7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mvel1</th>\n",
       "      <th>beta</th>\n",
       "      <th>betasq</th>\n",
       "      <th>chmom</th>\n",
       "      <th>dolvol</th>\n",
       "      <th>idiovol</th>\n",
       "      <th>indmom</th>\n",
       "      <th>mom1m</th>\n",
       "      <th>mom6m</th>\n",
       "      <th>mom12m</th>\n",
       "      <th>...</th>\n",
       "      <th>ms</th>\n",
       "      <th>baspread</th>\n",
       "      <th>ill</th>\n",
       "      <th>maxret</th>\n",
       "      <th>retvol</th>\n",
       "      <th>std_dolvol</th>\n",
       "      <th>std_turn</th>\n",
       "      <th>zerotrade</th>\n",
       "      <th>sic2</th>\n",
       "      <th>monthly_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>631250</th>\n",
       "      <td>5538.0000</td>\n",
       "      <td>0.838690</td>\n",
       "      <td>0.703401</td>\n",
       "      <td>-0.070731</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073765</td>\n",
       "      <td>0.175957</td>\n",
       "      <td>0.010256</td>\n",
       "      <td>-0.061654</td>\n",
       "      <td>-0.044106</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.148269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.025576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.102564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378923</th>\n",
       "      <td>5363.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.151794</td>\n",
       "      <td>-0.105263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.307875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941114</th>\n",
       "      <td>12384.9375</td>\n",
       "      <td>1.863429</td>\n",
       "      <td>3.472368</td>\n",
       "      <td>-1.030451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.121216</td>\n",
       "      <td>-0.006070</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>-0.442308</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.054857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.063535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.205128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480250</th>\n",
       "      <td>7330.0000</td>\n",
       "      <td>1.077943</td>\n",
       "      <td>1.161962</td>\n",
       "      <td>0.349352</td>\n",
       "      <td>4.925440</td>\n",
       "      <td>0.076073</td>\n",
       "      <td>0.103031</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.092675</td>\n",
       "      <td>-0.124950</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.118578</td>\n",
       "      <td>5.787460e-05</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.083604</td>\n",
       "      <td>0.894612</td>\n",
       "      <td>0.190640</td>\n",
       "      <td>1.278261e+01</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638100</th>\n",
       "      <td>7453.8750</td>\n",
       "      <td>0.530474</td>\n",
       "      <td>0.281403</td>\n",
       "      <td>0.729630</td>\n",
       "      <td>6.986797</td>\n",
       "      <td>0.063543</td>\n",
       "      <td>0.254838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.990470</td>\n",
       "      <td>0.590683</td>\n",
       "      <td>1.527273e+01</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563609</th>\n",
       "      <td>6539.0625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.410290</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.142803</td>\n",
       "      <td>-0.129032</td>\n",
       "      <td>-0.279070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.086110</td>\n",
       "      <td>2.557525e-06</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.063017</td>\n",
       "      <td>1.067567</td>\n",
       "      <td>4.167789</td>\n",
       "      <td>4.565217e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139779</th>\n",
       "      <td>583691.6250</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.495317</td>\n",
       "      <td>-0.385564</td>\n",
       "      <td>12.444891</td>\n",
       "      <td>0.029704</td>\n",
       "      <td>0.192585</td>\n",
       "      <td>0.010823</td>\n",
       "      <td>-0.048321</td>\n",
       "      <td>0.282428</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007335</td>\n",
       "      <td>4.878082e-09</td>\n",
       "      <td>0.019438</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.499158</td>\n",
       "      <td>0.658205</td>\n",
       "      <td>5.793432e-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455863</th>\n",
       "      <td>13530.0000</td>\n",
       "      <td>0.833536</td>\n",
       "      <td>0.694782</td>\n",
       "      <td>-0.192358</td>\n",
       "      <td>4.016383</td>\n",
       "      <td>0.048646</td>\n",
       "      <td>0.225989</td>\n",
       "      <td>0.108108</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.109661</td>\n",
       "      <td>1.817543e-04</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>0.024927</td>\n",
       "      <td>2.332372</td>\n",
       "      <td>0.346167</td>\n",
       "      <td>1.726974e-06</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.024390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122279</th>\n",
       "      <td>276734.5000</td>\n",
       "      <td>1.281812</td>\n",
       "      <td>1.643041</td>\n",
       "      <td>0.348567</td>\n",
       "      <td>10.969002</td>\n",
       "      <td>0.034572</td>\n",
       "      <td>0.090818</td>\n",
       "      <td>-0.020576</td>\n",
       "      <td>0.285364</td>\n",
       "      <td>0.170131</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017043</td>\n",
       "      <td>7.224012e-08</td>\n",
       "      <td>0.043290</td>\n",
       "      <td>0.015737</td>\n",
       "      <td>0.437626</td>\n",
       "      <td>0.460861</td>\n",
       "      <td>1.391896e-07</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.029412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929261</th>\n",
       "      <td>294337.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.113255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.095260</td>\n",
       "      <td>-0.032584</td>\n",
       "      <td>0.105970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017080</td>\n",
       "      <td>1.626744e-08</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.010533</td>\n",
       "      <td>0.534834</td>\n",
       "      <td>1.345278</td>\n",
       "      <td>4.896307e-08</td>\n",
       "      <td>59.0</td>\n",
       "      <td>-0.023952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1150885 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               mvel1      beta    betasq     chmom     dolvol   idiovol  \\\n",
       "631250     5538.0000  0.838690  0.703401 -0.070731        NaN  0.073765   \n",
       "378923     5363.5000       NaN       NaN       NaN        NaN       NaN   \n",
       "941114    12384.9375  1.863429  3.472368 -1.030451        NaN  0.121216   \n",
       "1480250    7330.0000  1.077943  1.161962  0.349352   4.925440  0.076073   \n",
       "1638100    7453.8750  0.530474  0.281403  0.729630   6.986797  0.063543   \n",
       "...              ...       ...       ...       ...        ...       ...   \n",
       "1563609    6539.0625       NaN       NaN       NaN   8.410290       NaN   \n",
       "139779   583691.6250  0.703787  0.495317 -0.385564  12.444891  0.029704   \n",
       "1455863   13530.0000  0.833536  0.694782 -0.192358   4.016383  0.048646   \n",
       "122279   276734.5000  1.281812  1.643041  0.348567  10.969002  0.034572   \n",
       "1929261  294337.5000       NaN       NaN       NaN  12.113255       NaN   \n",
       "\n",
       "           indmom     mom1m     mom6m    mom12m  ...   ms  baspread  \\\n",
       "631250   0.175957  0.010256 -0.061654 -0.044106  ...  NaN  0.148269   \n",
       "378923  -0.151794 -0.105263       NaN       NaN  ...  NaN  0.307875   \n",
       "941114  -0.006070  0.344828 -0.442308  0.035714  ...  NaN  0.054857   \n",
       "1480250  0.103031  0.052632  0.092675 -0.124950  ...  6.0  0.118578   \n",
       "1638100  0.254838  0.000000  0.500000  0.155556  ...  4.0  0.051282   \n",
       "...           ...       ...       ...       ...  ...  ...       ...   \n",
       "1563609 -0.142803 -0.129032 -0.279070       NaN  ...  NaN  0.086110   \n",
       "139779   0.192585  0.010823 -0.048321  0.282428  ...  NaN  0.007335   \n",
       "1455863  0.225989  0.108108  0.121212  0.608696  ...  6.0  0.109661   \n",
       "122279   0.090818 -0.020576  0.285364  0.170131  ...  NaN  0.017043   \n",
       "1929261 -0.095260 -0.032584  0.105970       NaN  ...  NaN  0.017080   \n",
       "\n",
       "                  ill    maxret    retvol  std_dolvol  std_turn     zerotrade  \\\n",
       "631250            NaN  0.051282  0.025576         NaN       NaN           NaN   \n",
       "378923            NaN  0.000000  0.023538         NaN       NaN           NaN   \n",
       "941114            NaN  0.193548  0.063535         NaN       NaN           NaN   \n",
       "1480250  5.787460e-05  0.222222  0.083604    0.894612  0.190640  1.278261e+01   \n",
       "1638100  0.000000e+00  0.000000  0.000000    1.990470  0.590683  1.527273e+01   \n",
       "...               ...       ...       ...         ...       ...           ...   \n",
       "1563609  2.557525e-06  0.095238  0.063017    1.067567  4.167789  4.565217e+00   \n",
       "139779   4.878082e-09  0.019438  0.005847    0.499158  0.658205  5.793432e-08   \n",
       "1455863  1.817543e-04  0.081081  0.024927    2.332372  0.346167  1.726974e-06   \n",
       "122279   7.224012e-08  0.043290  0.015737    0.437626  0.460861  1.391896e-07   \n",
       "1929261  1.626744e-08  0.023256  0.010533    0.534834  1.345278  4.896307e-08   \n",
       "\n",
       "         sic2  monthly_return  \n",
       "631250   51.0        0.102564  \n",
       "378923    NaN       -0.058824  \n",
       "941114   87.0        0.205128  \n",
       "1480250  36.0        0.000000  \n",
       "1638100  20.0        0.000000  \n",
       "...       ...             ...  \n",
       "1563609   NaN       -0.055556  \n",
       "139779    NaN        0.015418  \n",
       "1455863  78.0        0.024390  \n",
       "122279   37.0        0.029412  \n",
       "1929261  59.0       -0.023952  \n",
       "\n",
       "[1150885 rows x 96 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd1429d",
   "metadata": {},
   "source": [
    "## Note that the sample mean and standard deviation used to standardize the predictor variables are from the training set. This ensures that there is no information leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4d879dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = (X_train - X_train.mean()) / X_train.std()\n",
    "X_validate = (X_validate - X_train.mean()) / X_train.std()\n",
    "X_test = (X_test - X_train.mean()) / X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "583d3375",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedKFold, KFold, cross_val_score, train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e17b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall numpy -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6a9050",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy==1.15.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5d19610c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "41d3dcfc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2156878   -0.050000\n",
       "3866706    0.000000\n",
       "1770748    0.048611\n",
       "811456     0.130435\n",
       "1664830    0.058823\n",
       "             ...   \n",
       "2886971   -0.135560\n",
       "2095572    0.003009\n",
       "1547780   -0.081793\n",
       "2674393    0.073394\n",
       "3491323    0.137605\n",
       "Name: shifted_return, Length: 1359683, dtype: float64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "37942c5a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[80], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tree_regressor\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mmax_depth \u001b[38;5;241m<\u001b[39m depth:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m score \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree_regressor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mneg_mean_squared_error\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcrossvalidation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(depth, score)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mscore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:309\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m--> 309\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1076\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1077\u001b[0m     \u001b[38;5;66;03m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[0;32m   1078\u001b[0m     \u001b[38;5;66;03m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1082\u001b[0m     \u001b[38;5;66;03m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# remaining jobs.\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m-> 1085\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m   1086\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    289\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:732\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    730\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 732\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[0;32m    736\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:1320\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1292\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m \n\u001b[0;32m   1294\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1317\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1320\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:443\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    433\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    434\u001b[0m         splitter,\n\u001b[0;32m    435\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    440\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    441\u001b[0m     )\n\u001b[1;32m--> 443\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "crossvalidation = KFold(n_splits = 5, shuffle = True, random_state = 1)\n",
    "for depth in range(1, 10):\n",
    "    tree_regressor = tree.DecisionTreeRegressor(max_depth = depth, random_state = 1)\n",
    "    if tree_regressor.fit(X_train, y_train).tree_.max_depth < depth:\n",
    "        break\n",
    "    score = np.mean(cross_val_score(tree_regressor, X_train, y_train, scoring = 'neg_mean_squared_error',\n",
    "                                    cv = crossvalidation, n_jobs = 1))\n",
    "    print(depth, score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f1a81c",
   "metadata": {},
   "source": [
    "# Since technically, we are only tuning tree depth to be 1 or 2 and 2 is a little bit better than 1, we will fix tree depth as 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5927b346",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    # define number of trees to consider\n",
    "    n_trees = [100, 200, 300, 400, 500]\n",
    "    for n in n_trees:\n",
    "        models[str(n)] = AdaBoostRegressor(n_estimators=n)\n",
    "    return models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    # define the evaluation procedure\n",
    "    cv = KFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "    # evaluate the model and collect the results\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=1)\n",
    "    return scores\n",
    " \n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, X_validate, y_validate)\n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    # summarize the performance along the way\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d2a689",
   "metadata": {},
   "source": [
    "# We interrupted the kernel because the progress 100 -> 200 -> 300 trees has already shown a trend. It looks like 100 trees is the optimal choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cd4419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "    models = dict()\n",
    "    # define number of trees to consider\n",
    "    learning_rates = [0.01, 0.1]\n",
    "    for rate in learning_rates:\n",
    "        models[str(rate)] = AdaBoostRegressor(learning_rate=rate)\n",
    "    return models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "    # define the evaluation procedure\n",
    "    cv = KFold(n_splits = 3, shuffle = True, random_state = 1)\n",
    "    # evaluate the model and collect the results\n",
    "    scores = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=1)\n",
    "    return scores\n",
    " \n",
    "\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "    # evaluate the model\n",
    "    scores = evaluate_model(model, X_validate, y_validate)\n",
    "    # store the results\n",
    "    results.append(scores)\n",
    "    names.append(name)\n",
    "    # summarize the performance along the way\n",
    "    print('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22cc589",
   "metadata": {},
   "source": [
    "# For the learning rate, looks like taking smaller step is better. Therefore, we will choose 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e407736",
   "metadata": {},
   "source": [
    "# To summarize our best parameters\n",
    "## 1. Tree depth: 2\n",
    "## 2. Number of trees: 100\n",
    "## 3. Learning rate: 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a13b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge training and validating data to prepare for the final training\n",
    "X_train = X_train.append(X_validate)\n",
    "y_train = y_train.append(y_validate)\n",
    "\n",
    "base_estimator = DecisionTreeRegressor(max_depth=2)\n",
    "model = AdaBoostRegressor(base_estimator=base_estimator, n_estimators=100, learning_rate=0.01)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755a84ab",
   "metadata": {},
   "source": [
    "# Note to teammate: the model is ready. However, using the entire training set will take long, please use a smaller subset to get the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c7088d70-22c9-4e05-98ad-15df238e2c4e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nAdaBoostRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m AdaBoostRegressor(base_estimator\u001b[38;5;241m=\u001b[39mbase_estimator, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Fit the model on the sampled data\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_sample\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:135\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;66;03m# AdaBoost*.estimator is not validated yet\u001b[39;00m\n\u001b[0;32m    112\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    113\u001b[0m )\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    115\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a boosted classifier/regressor from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \n\u001b[0;32m    117\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 135\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[43m        \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_numeric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_regressor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(\n\u001b[0;32m    146\u001b[0m         sample_weight, X, np\u001b[38;5;241m.\u001b[39mfloat64, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, only_non_negative\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    147\u001b[0m     )\n\u001b[0;32m    148\u001b[0m     sample_weight \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m sample_weight\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1160\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1161\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nAdaBoostRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_full_train = pd.concat([X_train, X_validate])\n",
    "y_full_train = pd.concat([y_train, y_validate])\n",
    "\n",
    "# Shuffle the data and take a random 25% sample of the full training set\n",
    "X_sample, y_sample = shuffle(X_full_train, y_full_train, random_state=42)\n",
    "X_sample = X_sample.sample(frac=0.25, random_state=42)\n",
    "y_sample = y_sample.loc[X_sample.index]\n",
    "\n",
    "# Initialize the base estimator and the AdaBoostRegressor\n",
    "base_estimator = DecisionTreeRegressor(max_depth=2)\n",
    "model = AdaBoostRegressor(base_estimator=base_estimator, n_estimators=100, learning_rate=0.01)\n",
    "\n",
    "# Fit the model on the sampled data\n",
    "model.fit(X_sample, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "11f48631-734d-4910-90e3-579440d10a64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=2),\n",
       "                  learning_rate=0.01, n_estimators=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=2),\n",
       "                  learning_rate=0.01, n_estimators=100)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">base_estimator: DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=2)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=2)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=2),\n",
       "                  learning_rate=0.01, n_estimators=100)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sample, y_sample = shuffle(X_full_train, y_full_train, random_state=42)\n",
    "\n",
    "sample_frac = 0.25 #25% of data\n",
    "X_sample = X_sample.sample(frac=sample_frac, random_state=42)\n",
    "y_sample = y_sample.sample(frac=sample_frac, random_state=42)\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_sample_imputed = imputer.fit_transform(X_sample)\n",
    "\n",
    "model.fit(X_sample_imputed, y_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "415d5b5f-e346-4c97-9c97-d3cada4740ff",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[124], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m val_predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_sample_imputed) \u001b[38;5;66;03m#validate the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m val_mse \u001b[38;5;241m=\u001b[39m mean_squared_error(\u001b[43my_val\u001b[49m, val_predictions)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Mean Squared Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_mse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_sample_imputed) \u001b[38;5;66;03m# Testing the model\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_val' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "val_predictions = model.predict(X_sample_imputed) #validate the model\n",
    "val_mse = mean_squared_error(y_val, val_predictions)\n",
    "print(f'Validation Mean Squared Error: {val_mse}')\n",
    "\n",
    "\n",
    "test_predictions = model.predict(X_sample_imputed) # Testing the model\n",
    "test_mse = mean_squared_error(y_test, test_predictions)\n",
    "print(f'Test Mean Squared Error: {test_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42774a4",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a0872141",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.6-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from keras-tuner) (2.13.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from keras-tuner) (23.1)\n",
      "Requirement already satisfied: requests in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from keras-tuner) (2.28.1)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\urkes\\anaconda3\\lib\\site-packages (from requests->keras-tuner) (2023.11.17)\n",
      "Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
      "   ---------------------------------------- 0.0/128.9 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 61.4/128.9 kB 3.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 128.9/128.9 kB 2.5 MB/s eta 0:00:00\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f978a51b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras_tuner import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "260e363a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_start = '1957-01-31'\n",
    "training_end = '1989-12-31'\n",
    "validating_start = '1990-01-31'\n",
    "validating_end = '2004-12-31'\n",
    "testing_start = '2005-01-31'\n",
    "testing_end = '2020-12-31'\n",
    "\n",
    "training_mask = (filtered_data['date'] >= training_start) & (filtered_data['date'] <= training_end)\n",
    "training_index = filtered_data[training_mask].index.intersection(common_index)\n",
    "X_train = X.loc[training_index]\n",
    "y_train = y.loc[training_index]\n",
    "\n",
    "validating_mask = (filtered_data['date'] >= validating_start) & (filtered_data['date'] <= validating_end)\n",
    "validating_index = filtered_data[validating_mask].index.intersection(common_index)\n",
    "X_validate = X.loc[validating_index]\n",
    "y_validate = y.loc[validating_index]\n",
    "\n",
    "testing_mask = (filtered_data['date'] >= testing_start) & (filtered_data['date'] <= testing_end)\n",
    "testing_index = filtered_data[testing_mask].index.intersection(common_index)\n",
    "X_test = X.loc[testing_index]\n",
    "y_test = y.loc[testing_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "acdc98fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = (X_train - X_train.mean()) / X_train.std()\n",
    "X_validate = (X_validate - X_train.mean()) / X_train.std()\n",
    "X_test = (X_test - X_train.mean()) / X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e81a36c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "252/252 [==============================] - 6s 20ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/100\n",
      "252/252 [==============================] - 3s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/100\n",
      "252/252 [==============================] - 3s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/100\n",
      "252/252 [==============================] - 3s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/100\n",
      "252/252 [==============================] - 3s 12ms/step - loss: nan - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "modelnn = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dense(16, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(1)  # Assuming a regression problem; change accordingly for classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "modelnn.compile(optimizer=Adam(learning_rate=0.001),  # Start with 0.001\n",
    "              loss='mean_squared_error')  # Change loss function based on problem\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(patience=5)\n",
    "\n",
    "# Train the model\n",
    "history = modelnn.fit(X_train, y_train, epochs=100, batch_size=10000, validation_data=(X_validate, y_validate), callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6caf6488",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\hparam_tuning\\tuner0.json\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "0.01              |0.001             |learning_rate\n",
      "3.0476e-05        |0.00010248        |alpha\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 273, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 238, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 3875, in _assert_compile_was_called\n",
      "    raise RuntimeError(\n",
      "RuntimeError: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 273, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 238, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 3875, in _assert_compile_was_called\n    raise RuntimeError(\nRuntimeError: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[101], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Execute the search\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_validate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_validate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_validate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_validate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Get the optimal hyperparameters\u001b[39;00m\n\u001b[0;32m     36\u001b[0m best_hps \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_hyperparameters(num_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[1;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_trial_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py:338\u001b[0m, in \u001b[0;36mBaseTuner.on_trial_end\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_trial_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \n\u001b[0;32m    335\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 338\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\oracle.py:108\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m     LOCKS[oracle]\u001b[38;5;241m.\u001b[39macquire()\n\u001b[0;32m    107\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m thread_name\n\u001b[1;32m--> 108\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_acquire:\n\u001b[0;32m    110\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\oracle.py:586\u001b[0m, in \u001b[0;36mOracle.end_trial\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(trial):\n\u001b[0;32m    585\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_order\u001b[38;5;241m.\u001b[39mappend(trial\u001b[38;5;241m.\u001b[39mtrial_id)\n\u001b[1;32m--> 586\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_consecutive_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_trial(trial)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\oracle.py:543\u001b[0m, in \u001b[0;36mOracle._check_consecutive_failures\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    541\u001b[0m     consecutive_failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consecutive_failures \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials:\n\u001b[1;32m--> 543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    544\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of consecutive failures exceeded the limit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    546\u001b[0m         \u001b[38;5;241m+\u001b[39m (trial\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    547\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 273, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\base_tuner.py\", line 238, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras_tuner\\src\\engine\\hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"C:\\Users\\urkes\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py\", line 3875, in _assert_compile_was_called\n    raise RuntimeError(\nRuntimeError: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.\n"
     ]
    }
   ],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential([\n",
    "        Dense(32, activation='relu', input_shape=(X.shape[1],)),\n",
    "        BatchNormalization(),\n",
    "        Dense(16, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(1)\n",
    "    ])\n",
    "\n",
    "    # Tune the learning rate (from 0.001 to 0.01) and shrinkage parameter α (from 10^−5 to 10^−3)\n",
    "    learning_rate = hp.Choice('learning_rate', values=[0.001, 0.01])\n",
    "    alpha = hp.Float('alpha', min_value=1e-5, max_value=1e-3, sampling='log')\n",
    "\n",
    "    modelnn.compile(optimizer=Adam(learning_rate=learning_rate, beta_1=1-alpha),\n",
    "                  loss='mean_squared_error')\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create a tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',  \n",
    "    max_trials=20,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir',\n",
    "    project_name='hparam_tuning'\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# Execute the search\n",
    "tuner.search(X_validate, y_validate, epochs=100, batch_size=10000, validation_data=(X_validate, y_validate), callbacks=[early_stopping])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fbfe7b87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 5s 10ms/step - loss: nan\n",
      "Epoch 2/100\n",
      "387/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 3/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 4/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 5/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 6/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 7/100\n",
      "383/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 8/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 9/100\n",
      "385/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 10/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 11/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 12/100\n",
      "387/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 13/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 14/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 15/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 16/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 17/100\n",
      "383/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 18/100\n",
      "387/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 19/100\n",
      "385/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 20/100\n",
      "383/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 21/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 22/100\n",
      "385/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 23/100\n",
      "387/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 24/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 25/100\n",
      "385/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 26/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 27/100\n",
      "387/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 28/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 29/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 30/100\n",
      "385/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 31/100\n",
      "385/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 32/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 33/100\n",
      "385/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 34/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 35/100\n",
      "385/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 36/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 37/100\n",
      "385/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 38/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 39/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 40/100\n",
      "383/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 41/100\n",
      "387/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 42/100\n",
      "383/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 43/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 44/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 45/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 46/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 47/100\n",
      "383/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 48/100\n",
      "387/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 49/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 50/100\n",
      "387/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 51/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 52/100\n",
      "387/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 5s 12ms/step - loss: nan\n",
      "Epoch 53/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 54/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 55/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 56/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 57/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 58/100\n",
      "383/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 59/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 60/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 61/100\n",
      "387/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 62/100\n",
      "387/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 63/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 64/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 65/100\n",
      "385/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 66/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 67/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 68/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 69/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 70/100\n",
      "387/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 71/100\n",
      "385/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 72/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 73/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 74/100\n",
      "383/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 75/100\n",
      "385/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 5s 12ms/step - loss: nan\n",
      "Epoch 76/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 5s 12ms/step - loss: nan\n",
      "Epoch 77/100\n",
      "385/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 78/100\n",
      "388/388 [==============================] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 79/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 80/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 81/100\n",
      "387/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 82/100\n",
      "385/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 5s 12ms/step - loss: nan\n",
      "Epoch 83/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 84/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 5s 12ms/step - loss: nan\n",
      "Epoch 85/100\n",
      "383/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 86/100\n",
      "383/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 87/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 88/100\n",
      "385/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 89/100\n",
      "385/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 90/100\n",
      "387/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 91/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 92/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 93/100\n",
      "387/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 94/100\n",
      "385/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 95/100\n",
      "385/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n",
      "Epoch 96/100\n",
      "384/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 97/100\n",
      "387/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 98/100\n",
      "386/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 99/100\n",
      "383/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 10ms/step - loss: nan\n",
      "Epoch 100/100\n",
      "383/388 [============================>.] - ETA: 0s - loss: nanWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "388/388 [==============================] - 4s 11ms/step - loss: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x19380e8cfd0>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Merge training and validating data to prepare for the final trainings\n",
    "X_train = pd.concat([X_train, X_validate])\n",
    "y_train = pd.concat([y_train, y_validate])\n",
    "\n",
    "modelnn = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    BatchNormalization(),\n",
    "    Dense(16, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dense(1)  #Assuming a regression problem; change accordingly for classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "modelnn.compile(optimizer=Adam(learning_rate=0.001),  # Start with 0.001\n",
    "              loss='mean_squared_error')  # Change loss function based on problem\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(patience=5)\n",
    "\n",
    "# Train the model\n",
    "modelnn.fit(X_train, y_train, epochs=100, batch_size=10000, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8f86b5",
   "metadata": {},
   "source": [
    "# Note for teammate: The code for NN is written, but my Python version is not compatible with the tensorflow package. Please use your computer to run this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12ec570-000f-4416-a79e-b171c201eb84",
   "metadata": {
    "tags": []
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb12f780-e9c4-4749-8f37-ffe976513d06",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Question 3: Show how the models performs on the test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5b937a-51c6-4831-8788-2ba1fa572ece",
   "metadata": {
    "tags": []
   },
   "source": [
    "Adaboost model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "938dca3c-b0f4-4ed6-b22c-f04bad595514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean')  # or the strategy you used\n",
    "X_test_imputed = imputer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d70cbc4-68bd-47e3-997c-74cc7a8a6f36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict with AdaBoost Model\n",
    "y_pred_adaboost = model.predict(X_test_imputed)\n",
    "\n",
    "# Calculate R-squared for AdaBoost\n",
    "r2_adaboost = r2_score(y_test, y_pred_adaboost)\n",
    "print(f\"R-squared for AdaBoost model: {r2_adaboost}\")\n",
    "\n",
    "# Calculate Sharpe Ratios for AdaBoost\n",
    "deciles = pd.qcut(y_pred_adaboost, 10, labels=False)\n",
    "sharpe_ratios_adaboost = [np.mean(y_test[deciles == d]) / np.std(y_test[deciles == d]) for d in range(10)]\n",
    "print(\"Sharpe Ratios for each decile (AdaBoost):\", sharpe_ratios_adaboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499d462c-4726-44de-8366-07a2395b7c2f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29b6c4d-1d45-4d8f-a2d3-e0d4fc0dbc68",
   "metadata": {},
   "source": [
    "NN2 Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5ab662a6-a66e-4fee-bc38-e3e06163ed8f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35234/35234 [==============================] - 24s 690us/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[118], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m y_pred_nn \u001b[38;5;241m=\u001b[39m modelnn\u001b[38;5;241m.\u001b[39mpredict(X_test_imputed)\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Calculate R-squared for Neural Network\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m r2_nn \u001b[38;5;241m=\u001b[39m \u001b[43mr2_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_nn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mR-squared for Neural Network model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2_nn\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Calculate Sharpe Ratios for Neural Network\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:989\u001b[0m, in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[0;32m    848\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m    849\u001b[0m     {\n\u001b[0;32m    850\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    868\u001b[0m     force_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    869\u001b[0m ):\n\u001b[0;32m    870\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m \n\u001b[0;32m    872\u001b[0m \u001b[38;5;124;03m    Best possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    987\u001b[0m \u001b[38;5;124;03m    -inf\u001b[39;00m\n\u001b[0;32m    988\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 989\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    990\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\n\u001b[0;32m    991\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    992\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    994\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _num_samples(y_pred) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py:101\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     99\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    100\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m--> 101\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    104\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    956\u001b[0m         )\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 959\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    131\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    172\u001b[0m     )\n\u001b[1;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "y_pred_nn = modelnn.predict(X_test_imputed).flatten()\n",
    "\n",
    "# Calculate R-squared for Neural Network\n",
    "r2_nn = r2_score(y_test, y_pred_nn)\n",
    "print(f\"R-squared for Neural Network model: {r2_nn}\")\n",
    "\n",
    "# Calculate Sharpe Ratios for Neural Network\n",
    "deciles_nn = pd.qcut(y_pred_nn, 10, labels=False)\n",
    "sharpe_ratios_nn = [np.mean(y_test[deciles_nn == d]) / np.std(y_test[deciles_nn == d]) for d in range(10)]\n",
    "print(\"Sharpe Ratios for each decile (Neural Network):\", sharpe_ratios_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa594fb-faca-4ea1-8650-5285eb39a11d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for NaN in the imputed test set\n",
    "if np.isnan(X_test_imputed).any():\n",
    "    print(\"NaN values found in X_test_imputed\")\n",
    "else:\n",
    "    # Predict with Neural Network Model\n",
    "    y_pred_nn = modelnn.predict(X_test_imputed).flatten()\n",
    "\n",
    "    # Check for NaN in predictions\n",
    "    if np.isnan(y_pred_nn).any():\n",
    "        print(\"NaN values found in predictions\")\n",
    "    else:\n",
    "        # Calculate R-squared for Neural Network\n",
    "        r2_nn = r2_score(y_test, y_pred_nn)\n",
    "        print(f\"R-squared for Neural Network model: {r2_nn}\")\n",
    "\n",
    "        # Calculate Sharpe Ratios for Neural Network\n",
    "        deciles_nn = pd.qcut(y_pred_nn, 10, labels=False)\n",
    "        sharpe_ratios_nn = [np.mean(y_test[deciles_nn == d]) / np.std(y_test[deciles_nn == d]) for d in range(10)]\n",
    "        print(\"Sharpe Ratios for each decile (Neural Network):\", sharpe_ratios_nn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7420d4-2972-406d-930e-d4ba8cc3d14c",
   "metadata": {
    "tags": []
   },
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce4b392",
   "metadata": {},
   "source": [
    "# Outside source of help: ChatGPT, TA Session, Machine Learning Mastery"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
